# ELK with Bro-based Application Layer Packet Classifier
## Topology introduction 

`if you would like get to list command in a brief`

The application identification system will identify the application and generate logs by bro. The ELK is deployed at the remote end for all logs to be collected, analyzed, stored, and identifiable. The BRO is installed on a machine with an IP of 192.168.1.147 and the ELK is installed on a machine with an IP of 192.168.1.142. 

## Deployed system release   
Debian GNU/Linux 9.4.0   


## Convention Description  
``` 
ens33              a network interface name    
192.168.1.147      a network interface ipv4 address of bro device    
192.168.1.142      a network interface ipv4 address of ELK device 
``` 

## Install bro 

Because the metron-bro-plugin-kafka plugin will rely on the source code of the brother to compile and install. So, use the bro source code to install.

### Pre-install package  
```
~/src$ sudo apt-get install -y tcpdump git vim cmake make gcc g++ flex bison libpcap-dev python-dev swig zlib1g-dev libssl-dev dirmngr curl openjdk-8-jre 
```

### Download bro source and verify 
```
~/src$ wget https://www.zeek.org/downloads/bro-2.6.1.tar.gz.asc
~/src$ wget https://www.zeek.org/downloads/bro-2.6.1.tar.gz
~/src$ gpg --keyserver  pgp.mit.edu --recv-keys C68B494DF56ACC7E 
~/src$ gpg -v bro-2.6.1.tar.gz.asc
```

### Install 
```
~/src$ tar -xvf bro-2.6.1.tar.gz
~/src$ cd bro-2.6.1/
~/src$ ./configure
~/src$ make
~/src$ sudo make install 
``` 

### Set env value  

Bro install to dir is /usr/local/bro/bin/，add following line to /etc/bash.bashrc：
``` 
if [ -d /usr/local/bro/bin ];then
	PATH="/usr/local/bro/bin/:$PATH"
	export PATH
fi
``` 

### Set bro to systemd and satrt bro service 

```
~# cat > /etc/systemd/system/bro.service << EOL
[Unit]
Description=Bro
After=network.target

[Service]
ExecStartPre=/usr/local/bro/bin/broctl cleanup
ExecStartPre=/usr/local/bro/bin/broctl check
ExecStartPre=/usr/local/bro/bin/broctl install
ExecStart=/usr/local/bro/bin/broctl start
ExecStop=/usr/local/bro/bin/broctl stop
RestartSec=10s
Type=oneshot
RemainAfterExit=yes
TimeoutStopSec=600

[Install]
WantedBy=multi-user.target

EOL

~# systemctl daemon-reload   
~# systemctl enable bro  
~# systemctl start bro   
```



### Install Kafka 

#### Download kafka source 
```
wget https://www-us.apache.org/dist/kafka/2.1.0/kafka_2.12-2.1.0.tgz
wget https://www-us.apache.org/dist/kafka/2.1.0/kafka_2.12-2.1.0.tgz.asc

```

#### Verify 
```
~/src$ gpg --recv-keys  BEED4F6CB9F77D0E  
~/src$ gpg -v kafka_2.12-2.1.0.tgz.asc 
```

#### Install kafka and start service 
```
~/src$ tar -xvf kafka_2.12-2.1.0.tgz
~/src$ sudo mv kafka_2.12-2.1.0 /opt/kafka
~/src$ sudo sed -i '/^log.dirs/{s/=.*//;}' /opt/kafka/config/server.properties
~/src$ sudo sed -i 's/^log.dirs/log.dirs=\/var\/lib\/kafka/' /opt/kafka/config/server.properties
~/src$ sudo sed -i '$alisteners=bro://192.168.1.147:9092' /opt/kafka/config/server.properties 

~/src# cat > /etc/systemd/system/kafka.service << EOF
[Unit]
Description=Kafka Service
Wants=network.target
After=zookeeper.target

[Service]
ExecStart=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties
ExecReload=on-failure
Restart=always
User=root
Group=root
StandardOutput=syslog
StandardError=syslog

[Install]
WantedBy=multi-user.target
EOF

```

### Intall zookeeper

```
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.5.4-beta/zookeeper-3.5.4-beta.tar.gz
tar -xvf zookeeper-3.5.4-beta.tar.gz
sudo mv zookeeper-3.5.4-beta /opt/zookeeper
sudo cp ~/src/Debian-GNU-Linux-Profiles/NSM/ELK/packages/zoo.cfg /opt/zookeeper/conf/
sudo cp ~/src/Debian-GNU-Linux-Profiles/NSM/ELK/packages/zookeeper.service /etc/systemd/system/

```

#### Enable kafka service and start 

When the kafka service is started, the zookeeper service must have been started. 
``` 
sudo systemctl daemon-reload
sudo systemctl enable zookeeper
sudo systemctl start zookeeper

~/src$ sudo systemctl enable kafka 
~/src$ sudo systemctl start kafka
```

### Install metron-bro-plugin-kafka

#### Install librdkafka 
```
wget https://github.com/edenhill/librdkafka/archive/v0.11.6.tar.gz
sudo tar -xvf v0.11.6.tar.gz
cd librdkafka-0.11.6/
sudo ./configure --enable-sasl
sudo make

```

#### Build the plugin 
```
~/src$ git clone https://github.com/apache/metron-bro-plugin-kafka.git
~/src$ cd metron-bro-plugin-kafka
~/src/metron-bro-plugin-kafka$ ./configure --bro-dist=$HOME/src/bro-2.6.1/
~/src/metron-bro-plugin-kafka$ make 
~/src/metron-bro-plugin-kafka$ sudo make install
```
 
#### Ensure the plugin was installed 
```
~/src# bro -N Apache::Kafka 
``` 

### How to set bro logs to kafka 

please see this url. 

`https://github.com/hardenedlinux/hardenedlinux-bro-script/blob/master/scripts/bro-kafka.bro`

```

### Ensure bro logs to kafka 

following command to check:
```
~/src# systemctl status kafka | grep "Active:.active"
   Active: active (running) since Tue 2018-07-24 03:25:10 CST; 23min ago

~/src# netstat -ntpl  | grep 9092
tcp6       0      0 192.168.1.147:9092      :::*                    LISTEN      30913/java 

~/src$ ls /var/lib/kafka/bro-0/00000000000000000000.log 
```

## Install ELK 

### Pre-install package 

```
~$ sudo apt-get install -y openjdk-8-jre curl wget libgeoip-dev 
```

### Download ELK deb package and SHA512 (512-bit) checksums file 
```
~$ mkdir src; cd src 
~/src$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.5.4.deb 
~/src$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.5.4.deb.sha512 
~/src$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.5.4.deb 
~/src$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.5.4.deb.sha512 
~/src$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.5.4-amd64.deb 
~/src$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.5.4-amd64.deb.sha512 
```

### Verify ELK deb package 
```
~/src$ sha512sum -c elasticsearch-6.5.4.deb.sha512  
elasticsearch-6.5.4.deb: OK
~/src$ sha512sum -c logstash-6.5.4.deb.sha512 
logstash-6.3.0.deb: OK
~/src$ sha512sum -c kibana-6.5.4-amd64.deb.sha512 
kibana-6.5.4-amd64.deb: OK
```

### Install ELK deb package 
```
~/src$ sudo dpkg -i *.deb 
```

### Logstash configuration  
``` 
~/src$ echo config.reload.automatic: true |sudo tee -a /etc/logstash/logstash.yml
~/src$ echo config.reload.interval: 3s |sudo tee -a /etc/logstash/logstash.yml
```

### Geoip plugin & geoip template
<a id="org628d771"></a>

    
    sudo mv ~/src/Debian-GNU-Linux-Profiles/NSM/ELK/conf/test/elasticsearch-template-es7x.json /etc/logstash/conf.d
    sudo /usr/share/logstash/bin/logstash-plugin install --no-verify
    sudo /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-geoip

-   modified http<sub>template</sub> to es7x.json template &#x2014;> geo<sub>point</sub> function


<a id="org61454c5"></a>


### Create new logstash configuration 

The conf file will be generated for each type of log. The following is only an example of software: 

```
~/src# cat > /etc/logstash/conf.d/bro-software.conf << EOF 
input {
	kafka {
		topics => ["software"]
		group_id => "bro_logstash"
     		bootstrap_servers => "192.168.1.147:9092"
     		codec => json
     		auto_offset_reset => "earliest"
   	}
}

output {
	elasticsearch {
     		hosts => ["192.168.1.142:9200"]
		index => "bro-software"
		document_type => "software"
   	}
}

```
### GEOIP & urldecode 

```
NSM/ELK/conf/test/bro_http.conf

```
Other conf files are stored in the [logstash-conf](https://github.com/hardenedlinux/Debian-GNU-Linux-Profiles/tree/master/NSM/ELK/conf). Put these configuration files in the /etc/logstash/conf.d directory. 


### Elasticsearch configuration 
#### Bind Elasticsearch to localhost 
Following lines to /etc/elasticsearch/elasticsearch.yml:
```
network.host: "192.168.1.142" 
http.port:9200 
```

If elasticsearch service is remote, set the bind address to a specific IP.  

#### Ensure elasticsearch is working 
```
sudo systemctl start elasticsearch 
curl http://192.168.1.142:9200
{
  "name" : "VZDjFmY",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "xql3xQSbSvinXDIYchwswQ",
  "version" : {
    "number" : "6.3.0",
    "build_flavor" : "default",
    "build_type" : "deb",
    "build_hash" : "424e937",
    "build_date" : "2018-06-11T23:38:03.357887Z",
    "build_snapshot" : false,
    "lucene_version" : "7.3.1",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  },
  "tagline" : "You Know, for Search"
}
```

### Kibana configuration 

Enter the following lines to Kibana configuration file /etc/kibana/kibana.yml: 
``` 
server.port: 5601
server.host: "192.168.1.142"
elasticsearch.url: "http://192.168.1.142:9200"
```

### Start ELK service 
```
~/src$ sudo /bin/systemctl daemon-reload
~/src$ sudo /bin/systemctl enable elasticsearch.service logstash.service kibana.service
~/src$ sudo systemctl start elasticsearch.service kibana.service logstash.service
``` 

### Use Kibana 

#### Open Kibana 

Enter 192.168.1.142:5601 in the address bar of the browser. The page that opens is as shown below: 

![Open Kibana](./image/kibana-open.png)  

#### Create index pattern 

The following will be an example of creating a pattern with the software log. 

![Create_software_01](./image/create_pattern_1.png)   

![Create_software_02](./image/create_pattern_2.png)   

![Create_software_03](./image/create_pattern_3.png)   

![Create_software_04](./image/create_pattern_4.png)   

![Create_software_05](./image/create_pattern_5.png)   

#### Discover software index pattern 

![Create_software_01](./image/discover_software.png)   

#### Create visualize  

![Create_software_01](./image/create_visualize-1.png)   

![Create_software_01](./image/create_visualize-2.png)   

![Create_software_01](./image/create_visualize-3.png)   

![Create_software_01](./image/create_visualize-4.png)   

![Create_software_01](./image/create_visualize-5.png)   

![Create_software_01](./image/create_visualize-6.png)   


# PF<sub>RING</sub>


<a id="org26a0cc9"></a>

## Environment

    sudo apt-get install build-essential bison flex linux-headers-$(uname -r)


<a id="org7c46833"></a>

## clone Repo to local

     cd src
     git clone https://github.com/ntop/PF_RING.git
     cd PF_RING
    
     cd kernel
     ./configure
     make
     sudo make install
     cd ../userland/lib
     sudo make install
     sudo modprobe pf_ring
     #elevate as *root*
    ;;then
     sudo modprobe pf_ring
    
     ;;To check if you have everything you need, enter:
    
     modinfo pf_ring && cat /proc/net/pf_ring/info
    
     ;;;;;;;;;;;; the feedback likes this:
    
     filename:       /lib/modules/4.9.0-4-amd64/kernel/net/pf_ring/pf_ring.ko
     alias:          net-pf-27
     version:        7.1.0
     description:    Packet capture acceleration and analysis
     author:         ntop.org
     license:        GPL
     srcversion:     D173304DA43FD84C21E264E
     depends:
     vermagic:       4.9.0-4-amd64 SMP mod_unload modversions
     parm:           min_num_slots:Min number of ring slots (uint)
     parm:           perfect_rules_hash_size:Perfect rules hash size (uint)
     parm:           enable_tx_capture:Set to 1 to capture outgoing packets (uint)
     parm:           enable_frag_coherence:Set to 1 to handle fragments (flow coherence) in clusters (uint)
     parm:           enable_ip_defrag:Set to 1 to enable IP defragmentation(only rx traffic is defragmentead) (uint)
     parm:           quick_mode:Set to 1 to run at full speed but with upto one socket per interface (uint)
     parm:           force_ring_lock:Set to 1 to force ring locking (automatically enable with rss) (uint)
     parm:           enable_debug:Set to 1 to enable PF_RING debug tracing into the syslog, 2 for more verbosity (uint)
     parm:           transparent_mode:(deprecated) (uint)
     PF_RING Version          : 7.1.0 (dev:fcc142db7e2d5586a2923cc20f6a2cc4d7ebded5)
     Total rings              : 0
    
     Standard (non ZC) Options
     Ring slots               : 4096
     Slot version             : 17
     Capture TX               : Yes [RX+TX]
     IP Defragment            : No
     Socket Mode              : Standard
     Cluster Fragment Queue   : 0
     Cluster Fragment Discard : 0


<a id="org5546981"></a>

### Bro plugin to PF_RING

```
git clone https://github.com/ntop/bro-pf_ring.git
cd bro-pf_ring/
./configure --with-pfring=$HOME/src/PF_RING --bro-dist=$HOME/src/bro-2.6.1
make && sudo make install
bro -N Bro::PF_RING
```

## Node.cfg config
modify /usr/local/bro/etc/node.cfg, the example likes that:

```
[worker-1]
type=worker
host=localhost
interface=pf_ring::zc:eth1
lb_method=pf_ring
lb_procs=8
pin_cpus=0,1,2,3,4,5,6,7
```

<a id="orgb4a6fae"></a>

# Bro-script


<a id="org8163640"></a>

## download bro-script by bro-pkg


get more information `https://github.com/hardenedlinux/hardenedlinux-bro-script`



# Broker


<a id="org6825adf"></a>

## Installation

    wget https://www.bro.org/downloads/broker-1.1.1.tar.gz
    tar -xvf broker-1.1.1.tar.gz
    cd broker-1.1.1
    ./configure
    sudo make -j4 install


<a id="orgb479a3a"></a>

## Test

    mkdir ~/src/bro-test/
    git clone https://github.com/0ortmann/broker-application-templates.git


<a id="org327e937"></a>

# Pdns


<a id="org34dcc18"></a>

## Basic configuration


<a id="org976b23c"></a>

### Golang-environment

    wget https://dl.google.com/go/go1.11.2.linux-amd64.tar.gz
    tar -xvf  go1.11.2.linux-amd64.tar.gz
    sudo mv go /usr/local


<a id="org0cf20f9"></a>

### export go path & remove pdns repo to gopath/src

    cd ~/src/
    git clone https://github.com/JustinAzoff/bro-pdns
    cd bro-pdns
    make
    cd ..
    cp -r bro-pdns ~/go/src/.
    cd ~/go/src/bro-pdns
    make
    go build


<a id="org5771a4f"></a>

### Install postgresql & adder user "pdns" & password "pdns@321"

    sudo apt-get install postgresql
    sudo -u postgres createdb pdns
    sudo -u postgres createuser pdns
    sudo -u postgres psql
    alter user pdns with encrypted password '<pdns@321>';


<a id="org9e2be7c"></a>

### Install Java environment for jdbc by apt-get

    sudo apt-get install default-jre default-jdk libpostgresql-jdbc-java


<a id="org9cbb2f6"></a>

### check Driver class & postgresql-jdbc status

    ls /usr/share/java | grep postgresql-jdbc
    
    # postgresql-jdbc3.jar     #
    #     postgresql-jdbc4.jar #
    
    jar tf /usr/share/java/postgresql-jdbc4.jar | grep -i driver
    
    
      #################################################
      # org/postgresql/Driver$1.class   #           # #
      # org/postgresql/Driver$ConnectThread.class   # #
      # org/postgresql/Driver.class                 # #
      # org/postgresql/util/PSQLDriverVersion.class # #
      # META-INF/services/java.sql.Driver             #
      #################################################


<a id="orgd654ed1"></a>

### find dns log by dns that made a indexing from bro logs path

    sudo find /usr/local/bro/logs/*/dns* | sort -n | xargs -n 50 bro-pdns index


<a id="orgc0fd09e"></a>

## to ELK

-   install lostash plugin
    
        sudo /usr/share/logstash/bin/logstash-plugin install logstash-output-exec logstash-input-jdbc
-   Logstash configuration by jdbc connect to pg database:

ref: <https://www.elastic.co/blog/logstash-jdbc-input-plugin>

    input {
        jdbc {
            jdbc_connection_string => "jdbc:postgresql://localhost:5432/pdns"
             jdbc_user => "postgres"
             jdbc_password => "pdns@321"
             jdbc_validate_connection => true
             jdbc_driver_library => "/usr/share/java/postgresql-jdbc4.jar"
             statement => "SELECT * from tuples"
             jdbc_driver_class => "org.postgresql.Driver"
        }
    }
    output {
        elasticsearch {
            hosts => ["localhost:9200"]
            index => "contacts"
            document_type => "bro-pdns"
            document_id => "%{uid}"
        }
    }

-   debugging Logstash confin file
    
        sudo /usr/share/logstash/bin/logstash -f pdns.conf
        #finally output should be looks like that:
        # [INFO ] 2018-12-05 01:45:29.221 [Api Webserver] agent - Successfully started Logstash API endpoint {:port=>9601}
        # [INFO ] 2018-12-05 01:45:48.096 [[main]<jdbc] jdbc - (0.002015s) SELECT * from tuples
        # [INFO ] 2018-12-05 01:46:26.784 [[main]>worker11] pipeline - Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x7c052ede run>"}

-   Adding pdns index on kibana
    
    ![](./image/pdns_elk.jpg)


## Bro-osquery

please see this url get more information:

https://github.com/hardenedlinux/Debian-GNU-Linux-Profiles/blob/master/NSM/Osquery/bro-osquery.sh


## Reference  

https://www.bro.org   
http://try.bro.org/   
https://www.bro.org/sphinx/scripts/base/frameworks/software/main.bro.html   
https://www.bro.org/sphinx/scripts/base/bif/plugins/Bro_HTTP.events.bif.bro.html   
https://www.bro.org/sphinx/scripts/base/bif/plugins/Bro_SSL.events.bif.bro.html   
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html   
https://www.elastic.co/guide/en/logstash/6.3/plugins-outputs-elasticsearch.html   
https://www.elastic.co/    
https://github.com/apache/metron-bro-plugin-kafka
https://bro-package-manager.readthedocs.io/en/stable/source.html
https://www.elastic.co/blog/logstash-jdbc-input-plugin






